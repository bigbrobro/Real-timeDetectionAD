{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       eventID        account  \\\n",
      "0         4688        dcadmin   \n",
      "1         4674         hacked   \n",
      "2         5140            dc$   \n",
      "3         5140            dc$   \n",
      "4         5140            dc$   \n",
      "5         5140            dc$   \n",
      "6         5140            dc$   \n",
      "7         5140            dc$   \n",
      "8         5140        fsadmin   \n",
      "9         5140        fsadmin   \n",
      "10        5140        fsadmin   \n",
      "11        5140        fsadmin   \n",
      "12        5140            dc$   \n",
      "13        5140            dc$   \n",
      "14        5140            dc$   \n",
      "15        5140            dc$   \n",
      "16        5140  local service   \n",
      "17        5140        filesv$   \n",
      "18        5140        filesv$   \n",
      "19        5140            dc$   \n",
      "20        5140            dc$   \n",
      "21        5140  local service   \n",
      "22        5140        filesv$   \n",
      "23        5140        filesv$   \n",
      "24        5140            dc$   \n",
      "25        5140            dc$   \n",
      "26        5140            dc$   \n",
      "27        5140            dc$   \n",
      "28        5140            dc$   \n",
      "29        5140            dc$   \n",
      "...        ...            ...   \n",
      "40840     5140            dc$   \n",
      "40841     4688            dc$   \n",
      "40842     4688            dc$   \n",
      "40843     4688            dc$   \n",
      "40844     4688            dc$   \n",
      "40845     4688            dc$   \n",
      "40846     4688            dc$   \n",
      "40847     4688            dc$   \n",
      "40848     4688            dc$   \n",
      "40849     4688            dc$   \n",
      "40850     4688            dc$   \n",
      "40851     4688            dc$   \n",
      "40852     4688            dc$   \n",
      "40853     4688            dc$   \n",
      "40854     4688            dc$   \n",
      "40855     4688            dc$   \n",
      "40856     4688            dc$   \n",
      "40857     4688            dc$   \n",
      "40858     4688            dc$   \n",
      "40859     4688            dc$   \n",
      "40860     4688            dc$   \n",
      "40861     4688            dc$   \n",
      "40862     4688            dc$   \n",
      "40863     4688            dc$   \n",
      "40864     4688            dc$   \n",
      "40865     4688            dc$   \n",
      "40866     4688            dc$   \n",
      "40867     4688            dc$   \n",
      "40868     4688        dcadmin   \n",
      "40869     4688        dcadmin   \n",
      "\n",
      "                                                 process objectname   target  \n",
      "0                             c:\\windows\\system32\\at.exe        NaN  outlier  \n",
      "1                       c:\\windows\\system32\\services.exe   psexesvc  outlier  \n",
      "2                                                    NaN        NaN    train  \n",
      "3                                                    NaN        NaN    train  \n",
      "4                                                    NaN        NaN    train  \n",
      "5                                                    NaN        NaN    train  \n",
      "6                                                    NaN        NaN    train  \n",
      "7                                                    NaN        NaN    train  \n",
      "8                                                    NaN        NaN    train  \n",
      "9                                                    NaN        NaN    train  \n",
      "10                                                   NaN        NaN    train  \n",
      "11                                                   NaN        NaN    train  \n",
      "12                                                   NaN        NaN    train  \n",
      "13                                                   NaN        NaN    train  \n",
      "14                                                   NaN        NaN    train  \n",
      "15                                                   NaN        NaN    train  \n",
      "16                                                   NaN        NaN    train  \n",
      "17                                                   NaN        NaN    train  \n",
      "18                                                   NaN        NaN    train  \n",
      "19                                                   NaN        NaN    train  \n",
      "20                                                   NaN        NaN    train  \n",
      "21                                                   NaN        NaN    train  \n",
      "22                                                   NaN        NaN    train  \n",
      "23                                                   NaN        NaN    train  \n",
      "24                                                   NaN        NaN    train  \n",
      "25                                                   NaN        NaN    train  \n",
      "26                                                   NaN        NaN    train  \n",
      "27                                                   NaN        NaN    train  \n",
      "28                                                   NaN        NaN    train  \n",
      "29                                                   NaN        NaN    train  \n",
      "...                                                  ...        ...      ...  \n",
      "40840                                                NaN        NaN    train  \n",
      "40841                    c:\\windows\\system32\\svchost.exe        NaN    train  \n",
      "40842  c:\\program files (x86)\\google\\update\\googleupd...        NaN    train  \n",
      "40843  c:\\program files (x86)\\google\\update\\googleupd...        NaN    train  \n",
      "40844  c:\\program files (x86)\\google\\update\\1.3.33.17...        NaN    train  \n",
      "40845  c:\\program files (x86)\\google\\update\\1.3.33.17...        NaN    train  \n",
      "40846              c:\\windows\\system32\\wbem\\wmiapsrv.exe        NaN    train  \n",
      "40847                            c:\\windows\\psexesvc.exe        NaN    train  \n",
      "40848                    c:\\windows\\system32\\dllhost.exe        NaN    train  \n",
      "40849                        c:\\windows\\system32\\cmd.exe        NaN    train  \n",
      "40850                    c:\\windows\\system32\\conhost.exe        NaN    train  \n",
      "40851               c:\\windows\\system32\\wbem\\wmiadap.exe        NaN    train  \n",
      "40852                            c:\\windows\\psexesvc.exe        NaN    train  \n",
      "40853                    c:\\windows\\system32\\dllhost.exe        NaN    train  \n",
      "40854                        c:\\windows\\system32\\cmd.exe        NaN    train  \n",
      "40855                    c:\\windows\\system32\\conhost.exe        NaN    train  \n",
      "40856                            c:\\windows\\psexesvc.exe        NaN    train  \n",
      "40857                    c:\\windows\\system32\\dllhost.exe        NaN    train  \n",
      "40858                        c:\\windows\\system32\\cmd.exe        NaN    train  \n",
      "40859                    c:\\windows\\system32\\conhost.exe        NaN    train  \n",
      "40860                            c:\\windows\\psexesvc.exe        NaN    train  \n",
      "40861                    c:\\windows\\system32\\dllhost.exe        NaN    train  \n",
      "40862                        c:\\windows\\system32\\cmd.exe        NaN    train  \n",
      "40863                    c:\\windows\\system32\\conhost.exe        NaN    train  \n",
      "40864                            c:\\windows\\psexesvc.exe        NaN    train  \n",
      "40865                    c:\\windows\\system32\\dllhost.exe        NaN    train  \n",
      "40866                        c:\\windows\\system32\\cmd.exe        NaN    train  \n",
      "40867                    c:\\windows\\system32\\conhost.exe        NaN    train  \n",
      "40868                       c:\\windows\\system32\\aaaa.exe        NaN  outlier  \n",
      "40869      c:\\temp\\tools\\mimikatz_trunk\\x64\\mimikatz.exe        NaN  outlier  \n",
      "\n",
      "[40870 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('eventlog_gui9.csv')\n",
    "print(df) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-class SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def learning(eventid, df, nu, gamma):\n",
    "    \n",
    "    df = df[df.eventID == eventid]\n",
    "    data_dummies = pd.get_dummies(df.iloc[:,1:])\n",
    "    data_dummies = pd.concat([df.iloc[:,0], data_dummies], axis=1)\n",
    "    data_dummies.to_csv('data_dummies_' + str(eventid) + '.csv')\n",
    "\n",
    "    if 'train' not in df.target.values:\n",
    "        print('No train value in the target column')\n",
    "        print('')\n",
    "        return\n",
    "\n",
    "    if 'test' not in df.target.values:\n",
    "        print('No test value in the target column')\n",
    "        print('')\n",
    "        return\n",
    "    \n",
    "    if 'outlier' not in df.target.values:\n",
    "        print('No outlier value in the target column')\n",
    "        print('')\n",
    "        return\n",
    "\n",
    "    data_normal = data_dummies[data_dummies.target_train == 1]\n",
    "    data_test = data_dummies[data_dummies.target_test == 1]\n",
    "    data_outliers = data_dummies[data_dummies.target_outlier == 1]\n",
    "    X_train = data_normal.ix[:, :-3].values\n",
    "    X_test = data_test.ix[:, :-3].values\n",
    "    X_outliers = data_outliers.ix[:, :-3].values\n",
    "    \n",
    "    X_all = data_dummies.ix[:, :-3].values\n",
    "    X_index = data_dummies.ix[:, -3:].values\n",
    "    \n",
    "    clf = svm.OneClassSVM(nu=nu, kernel=\"rbf\", gamma=gamma)\n",
    "    clf.fit(X_train)\n",
    "    \n",
    "    #n_correct_test is True Negative\n",
    "    #n_error_test is False Positive\n",
    "    #n_correct_outliers is True Positive\n",
    "    #n_error_outliers is False Negative\n",
    "\n",
    "    X_pred_train = clf.predict(X_train)\n",
    "    X_pred_test = clf.predict(X_test)\n",
    "    X_pred_outliers = clf.predict(X_outliers)\n",
    "    n_correct_train = X_pred_train[X_pred_train == 1].size\n",
    "    n_error_train = X_pred_train[X_pred_train == -1].size\n",
    "    n_correct_test = X_pred_test[X_pred_test == 1].size\n",
    "    n_error_test = X_pred_test[X_pred_test == -1].size\n",
    "    n_correct_outliers = X_pred_outliers[X_pred_outliers == -1].size\n",
    "    n_error_outliers = X_pred_outliers[X_pred_outliers == 1].size\n",
    "    recall = n_correct_outliers / (n_correct_outliers + n_error_outliers)\n",
    "    precision = n_correct_outliers / (n_correct_outliers + n_error_test)\n",
    "    specificity = n_correct_test / (n_correct_test + n_error_test)\n",
    "    accuracy = (n_correct_test + n_correct_outliers) / (n_correct_test + n_error_test + n_correct_outliers + n_error_outliers)\n",
    "    f_value = (2 * n_correct_outliers) / (2 * n_correct_outliers + n_error_test + n_error_outliers)\n",
    "    \n",
    "    print('svm.OneClassSVM(nu=' + str(nu) + ', kernel=\"rbf\", gamma=' + str(gamma) + ')')\n",
    "    print('Training Correct: ' + str(n_correct_train))\n",
    "    print('Training Error: ' + str(n_error_train))\n",
    "    print('True Negative: ' + str(n_correct_test))\n",
    "    print('False Positive: ' + str(n_error_test))\n",
    "    print('True Positive: ' + str(n_correct_outliers))\n",
    "    print('False Negative: ' + str(n_error_outliers))\n",
    "    print('Recall: ' + str(recall))\n",
    "    print('Precision: ' + str(precision))\n",
    "    print('Specificity: ' + str(specificity))\n",
    "    print('Accuracy: ' + str(accuracy))\n",
    "    print('F_Value: ' + str(f_value))\n",
    "    print('N: ' + str(n_correct_train+n_error_train+n_correct_test+n_error_test+n_correct_outliers+n_error_outliers))\n",
    "    print('')\n",
    "    \n",
    "    X_train_result = np.concatenate((df[df['target'] == 'train'], X_pred_train[np.newaxis, :].T), axis=1)\n",
    "    X_test_result = np.concatenate((df[df['target'] == 'test'], X_pred_test[np.newaxis, :].T), axis=1)\n",
    "    X_outliers_result = np.concatenate((df[df['target'] == 'outlier'], X_pred_outliers[np.newaxis, :].T), axis=1)\n",
    "\n",
    "    with open('X_train_result' + str(eventid) + '.csv', 'w') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows(X_train_result)\n",
    "    \n",
    "    with open('X_test_result' + str(eventid) + '.csv', 'w') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows(X_test_result)\n",
    "\n",
    "    with open('X_outliers_result' + str(eventid) + '.csv', 'w') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows(X_outliers_result)\n",
    "        \n",
    "    #print('PCA')\n",
    "    #pca = PCA(n_components=2)\n",
    "    #X_pca = pca.fit_transform(X_all)\n",
    "\n",
    "    #plt.figure()\n",
    "    #plt.scatter(X_pca[:,0], X_pca[:,1], c=X_index)\n",
    "    #plt.title('Red:' + data_dummies.columns[-3] + '  Green:' + data_dummies.columns[-2] + '  Blue:' + data_dummies.columns[-1])\n",
    "    #plt.show()\n",
    "\n",
    "    joblib.dump(clf, 'ocsvm_gt_' + str(eventid) + '.pkl') \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm.OneClassSVM(nu=0.1, kernel=\"rbf\", gamma=0.1)\n",
      "Training Correct: 2103\n",
      "Training Error: 524\n",
      "True Negative: 694\n",
      "False Positive: 183\n",
      "True Positive: 96\n",
      "False Negative: 5\n",
      "Recall: 0.9504950495049505\n",
      "Precision: 0.34408602150537637\n",
      "Specificity: 0.7913340935005702\n",
      "Accuracy: 0.8077709611451943\n",
      "F_Value: 0.5052631578947369\n",
      "N: 3605\n",
      "\n",
      "svm.OneClassSVM(nu=0.1, kernel=\"rbf\", gamma=0.01)\n",
      "Training Correct: 1944\n",
      "Training Error: 683\n",
      "True Negative: 726\n",
      "False Positive: 151\n",
      "True Positive: 98\n",
      "False Negative: 3\n",
      "Recall: 0.9702970297029703\n",
      "Precision: 0.39357429718875503\n",
      "Specificity: 0.8278221208665907\n",
      "Accuracy: 0.8425357873210634\n",
      "F_Value: 0.56\n",
      "N: 3605\n",
      "\n",
      "svm.OneClassSVM(nu=0.1, kernel=\"rbf\", gamma=0.001)\n",
      "Training Correct: 2164\n",
      "Training Error: 463\n",
      "True Negative: 757\n",
      "False Positive: 120\n",
      "True Positive: 96\n",
      "False Negative: 5\n",
      "Recall: 0.9504950495049505\n",
      "Precision: 0.4444444444444444\n",
      "Specificity: 0.863169897377423\n",
      "Accuracy: 0.8721881390593047\n",
      "F_Value: 0.6056782334384858\n",
      "N: 3605\n",
      "\n",
      "svm.OneClassSVM(nu=0.01, kernel=\"rbf\", gamma=0.1)\n",
      "Training Correct: 2384\n",
      "Training Error: 243\n",
      "True Negative: 820\n",
      "False Positive: 57\n",
      "True Positive: 92\n",
      "False Negative: 9\n",
      "Recall: 0.9108910891089109\n",
      "Precision: 0.6174496644295302\n",
      "Specificity: 0.935005701254276\n",
      "Accuracy: 0.9325153374233128\n",
      "F_Value: 0.736\n",
      "N: 3605\n",
      "\n",
      "svm.OneClassSVM(nu=0.01, kernel=\"rbf\", gamma=0.01)\n",
      "Training Correct: 1967\n",
      "Training Error: 660\n",
      "True Negative: 699\n",
      "False Positive: 178\n",
      "True Positive: 92\n",
      "False Negative: 9\n",
      "Recall: 0.9108910891089109\n",
      "Precision: 0.34074074074074073\n",
      "Specificity: 0.7970353477765109\n",
      "Accuracy: 0.8087934560327198\n",
      "F_Value: 0.49595687331536387\n",
      "N: 3605\n",
      "\n",
      "svm.OneClassSVM(nu=0.01, kernel=\"rbf\", gamma=0.001)\n",
      "Training Correct: 2199\n",
      "Training Error: 428\n",
      "True Negative: 747\n",
      "False Positive: 130\n",
      "True Positive: 90\n",
      "False Negative: 11\n",
      "Recall: 0.8910891089108911\n",
      "Precision: 0.4090909090909091\n",
      "Specificity: 0.8517673888255416\n",
      "Accuracy: 0.8558282208588958\n",
      "F_Value: 0.5607476635514018\n",
      "N: 3605\n",
      "\n",
      "svm.OneClassSVM(nu=0.001, kernel=\"rbf\", gamma=0.1)\n",
      "Training Correct: 1835\n",
      "Training Error: 792\n",
      "True Negative: 678\n",
      "False Positive: 199\n",
      "True Positive: 93\n",
      "False Negative: 8\n",
      "Recall: 0.9207920792079208\n",
      "Precision: 0.3184931506849315\n",
      "Specificity: 0.7730900798175598\n",
      "Accuracy: 0.7883435582822086\n",
      "F_Value: 0.4732824427480916\n",
      "N: 3605\n",
      "\n",
      "svm.OneClassSVM(nu=0.001, kernel=\"rbf\", gamma=0.01)\n",
      "Training Correct: 2115\n",
      "Training Error: 512\n",
      "True Negative: 781\n",
      "False Positive: 96\n",
      "True Positive: 92\n",
      "False Negative: 9\n",
      "Recall: 0.9108910891089109\n",
      "Precision: 0.48936170212765956\n",
      "Specificity: 0.8905359179019384\n",
      "Accuracy: 0.8926380368098159\n",
      "F_Value: 0.6366782006920415\n",
      "N: 3605\n",
      "\n",
      "svm.OneClassSVM(nu=0.001, kernel=\"rbf\", gamma=0.001)\n",
      "Training Correct: 393\n",
      "Training Error: 2234\n",
      "True Negative: 88\n",
      "False Positive: 789\n",
      "True Positive: 99\n",
      "False Negative: 2\n",
      "Recall: 0.9801980198019802\n",
      "Precision: 0.11148648648648649\n",
      "Specificity: 0.10034207525655645\n",
      "Accuracy: 0.19120654396728015\n",
      "F_Value: 0.20020222446916078\n",
      "N: 3605\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nu_list = [0.1, 0.01, 0.001]\n",
    "gamma_list = [0.1, 0.01, 0.001]\n",
    "\n",
    "for nu in nu_list:\n",
    "    for gamma in gamma_list:\n",
    "        #learning(4672, df, nu, gamma)\n",
    "        #learning(4673, df, nu, gamma)\n",
    "        #learning(4674, df, nu, gamma)\n",
    "        learning(4688, df, nu, gamma)\n",
    "        #learning(4768, df, nu, gamma)\n",
    "        #learning(4769, df, nu, gamma)\n",
    "        #learning(5140, df, nu, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm.OneClassSVM(nu=0.01, kernel=\"rbf\", gamma=0.1)\n",
      "Training Correct: 2384\n",
      "Training Error: 243\n",
      "True Negative: 822\n",
      "False Positive: 59\n",
      "True Positive: 90\n",
      "False Negative: 7\n",
      "Recall: 0.9278350515463918\n",
      "Precision: 0.6040268456375839\n",
      "Specificity: 0.9330306469920545\n",
      "Accuracy: 0.9325153374233128\n",
      "F_Value: 0.7317073170731707\n",
      "N: 3605\n",
      "\n"
     ]
    }
   ],
   "source": [
    "learning(4688, df, 0.01, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm.OneClassSVM(nu=0.001, kernel=\"rbf\", gamma=0.1)\n",
      "Training Correct: 401\n",
      "Training Error: 72\n",
      "True Negative: 45\n",
      "False Positive: 5\n",
      "True Positive: 143\n",
      "False Negative: 0\n",
      "Recall: 1.0\n",
      "Precision: 0.9662162162162162\n",
      "Specificity: 0.9\n",
      "Accuracy: 0.9740932642487047\n",
      "F_Value: 0.9828178694158075\n",
      "N: 666\n",
      "\n"
     ]
    }
   ],
   "source": [
    "learning(4674, df, 0.001, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
